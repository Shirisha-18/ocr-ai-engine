# ğŸ“ OCR-AI-Engine

> Extract text from images and scanned documents using **Google Cloud Vision API**.  
> Designed as a foundation for AI-powered OCR pipelines and future RAG / LLM integrations.

---

## ğŸ“ Project Structure


```
â”œâ”€â”€ LICENSE            <- Open-source license if one is chosen
â”œâ”€â”€ README.md          <- The top-level README for developers using this project
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ external       <- Data from third party sources
â”‚   â”œâ”€â”€ interim        <- Intermediate data that has been transformed
â”‚   â”œâ”€â”€ processed      <- The final, canonical data sets for modeling
â”‚   â””â”€â”€ raw            <- The original, immutable data dump
â”‚
â”œâ”€â”€ models             <- Trained and serialized models, model predictions, or model summaries
â”‚
â”œâ”€â”€ notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),
â”‚                         the creator's initials, and a short `-` delimited description, e.g.
â”‚                         `1.0-jqp-initial-data-exploration`
â”‚
â”œâ”€â”€ references         <- Data dictionaries, manuals, and all other explanatory materials
â”‚
â”œâ”€â”€ reports            <- Generated analysis as HTML, PDF, LaTeX, etc.
â”‚   â””â”€â”€ figures        <- Generated graphics and figures to be used in reporting
â”‚
â”œâ”€â”€ requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.
â”‚                         generated with `pip freeze > requirements.txt`
â”‚
â””â”€â”€ src                         <- Source code for this project
    â”‚
    â”œâ”€â”€ __init__.py             <- Makes src a Python module
    â”‚
    â”œâ”€â”€ config.py               <- Store useful variables and configuration
    â”‚
    â”œâ”€â”€ dataset.py              <- Scripts to download or generate data
    â”‚
    â”œâ”€â”€ features.py             <- Code to create features for modeling
    â”‚
    â”‚    
    â”œâ”€â”€ modeling                
    â”‚   â”œâ”€â”€ __init__.py 
    â”‚   â”œâ”€â”€ predict.py          <- Code to run model inference with trained models          
    â”‚   â””â”€â”€ train.py            <- Code to train models
    â”‚
    â”œâ”€â”€ plots.py                <- Code to create visualizations 
    â”‚
    â””â”€â”€ services                <- Service classes to connect with external platforms, tools, or APIs
        â””â”€â”€ __init__.py 
```

--------

# ğŸ“ OCR-AI-Engine

![Python](https://img.shields.io/badge/python-3.12-blue)
![Google Cloud](https://img.shields.io/badge/GCP-Vision_API-orange)
![License](https://img.shields.io/badge/license-MIT-green)

> Extract text from images and scanned documents using **Google Cloud Vision API**.  
> Designed as a foundation for AI-powered OCR pipelines and future RAG / LLM integrations.

---

## ğŸ“ Project Structure

â”œâ”€â”€ LICENSE <- Open-source license if one is chosen
â”œâ”€â”€ README.md <- This file
â”œâ”€â”€ data
â”‚ â”œâ”€â”€ external <- Data from third party sources
â”‚ â”œâ”€â”€ interim <- Intermediate data that has been transformed
â”‚ â”œâ”€â”€ processed <- The final, canonical data sets for modeling
â”‚ â””â”€â”€ raw <- Original, immutable data dump (images for OCR)
â”‚
â”œâ”€â”€ models <- Trained and serialized models, model predictions, or summaries
â”‚
â”œâ”€â”€ notebooks <- Jupyter notebooks (optional)
â”‚
â”œâ”€â”€ references <- Data dictionaries, manuals, explanatory materials
â”‚
â”œâ”€â”€ reports <- Generated analysis (HTML, PDF, LaTeX, etc.)
â”‚ â””â”€â”€ figures <- Graphics and figures
â”‚
â”œâ”€â”€ requirements.txt <- Optional dependencies list
â”‚
â””â”€â”€ src <- Source code
â”œâ”€â”€ init.py <- Makes src a Python module
â”œâ”€â”€ google_cloud_vision.py <- Main OCR script
â”œâ”€â”€ my_timer.py <- Helper timer
â”œâ”€â”€ vision_key.json <- Google Cloud Vision API credentials (ignored in git)
â””â”€â”€ services <- Optional service modules for API connections

yaml
Copy code

---

## âš™ï¸ Environment Setup

1. **Create and activate Conda environment**
```bash
conda create -n gcp-cloud-vision python=3.12 -y
conda activate gcp-cloud-vision
Install required packages

bash
Copy code
conda install -c conda-forge pillow=10.1.0 pandas=2.1.2 google-cloud-vision=3.4.5 scikit-learn=1.3.2 ipykernel jupyterlab notebook -y
Register the environment in Jupyter (optional)

bash
Copy code
python -m ipykernel install --user --name=gcp-cloud-vision
ğŸ”‘ Google Cloud Vision Setup
Go to Google Cloud Console

Create a project and enable Vision API

Under IAM & Admin â†’ Service Accounts, create a service account key

Download the JSON key and rename it to:

pgsql
Copy code
vision_key.json
Place it in:

bash
Copy code
ocr-ai-engine/src/
Ensure .gitignore includes:

bash
Copy code
# Google Cloud Vision API key
vision_key.json
ğŸ–¼ï¸ Add Images
Place all images in:

bash
Copy code
ocr-ai-engine/data/raw/
Supported formats: .jpg, .jpeg, .png, .tif, .bmp

Example:

bash
Copy code
data/raw/
â”œâ”€â”€ patent1.jpg
â”œâ”€â”€ document2.png
â”œâ”€â”€ receipt3.jpeg
â–¶ï¸ Run the OCR Script
From the project root, run:

bash
Copy code
conda activate gcp-cloud-vision
python src/google_cloud_vision.py
The program prints each image name and extracted text.

Execution time is displayed at the end.

ğŸ§¾ Example Output
vbnet
Copy code
==============================
Image: patent1.jpg
Detected text:
United States Patent Office
...
Elapsed time to run main: 5.4321 seconds
âš ï¸ Troubleshooting
Error	Fix
DefaultCredentialsError	Ensure vision_key.json path is correct in src/
403 Permission Denied	Enable Vision API & billing in GCP
FileNotFoundError	Confirm images are in data/raw/
ModuleNotFoundError: google.cloud	Reinstall: conda install -c conda-forge google-cloud-vision

ğŸŒŸ Future Enhancements
Docker container for reproducibility

Integration with LangChain / RAG for text analysis

Store OCR results in database / JSON

Large-scale batch processing with Google Cloud Storage

ğŸ›¡ï¸ Security
Never commit vision_key.json

Always include it in .gitignore

